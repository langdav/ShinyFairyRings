---
title: "Untitled"
author: "David Langenohl"
date: "16 3 2021"
output: html_document
---

<style type="text/css">

body{ /* Normal  */
      font-size: 20px;
      font-family: "Times New Roman", Times, serif;
      color: Black;
  }
  
</style>

Looking at the pictures above, you can see three results compared to the RGB-picture on the far right (which is linear-stretched, as this leads to a better visibility of the *Fairy Rings*): *U-Net*, *SegOptim* with RGB-only, *SegOptim* with the 17-layer stack (including the *green* channel) + *blue* and *green* channels. The RGB-*SegOptim*-Model was trained for a more in-depth comparison to the *U-Net* model, as the *U-Net* algorithm did also just use the three RGB-layers. So, comparing those two models' results it is unambiguous that *U-Net* (far left) did an undisputedly better job than SegOptim (middle-left), when solely relying on the RGB-layers. On the other hand, comparing the *U-Net* result with those of the SegOptim trained with the large stack, it remains less clear. Looking at both images reveals, that *U-Net* delivered cleaner structures, whereas the SegOptim algorithm created a noisier image with a lot of small points, classified as *Fairy Ring*, which do not seem to really belong to a larger *Fairy Ring* structure. On the other hand, *U-Net* is missing some structures, that where classified as *Fairy Ring* by *SegOptim* and that seem to belong to a *Fairy Ring*, when comparing it to the RGB-image. However, to validate our findings, we used the validation raster on the right. Here, a section of our area of interest was classified by hand (just like it was done for the training areas). It was then compared to the same section, but this tame classified by the algorithms. From this comparison, we gained the models' accuracy and their F1 values.

Looking into the models' accuracies, results in a strange picture at first:  
*U-Net*: **0.94**, *SegOptim* with full stack: **0.8**, *SegOptim* with RGB-stack: **0.85**  
*U-Net* reveals to have the highest accuracy, which does not seem suprising, given the image above (and the one in the tool below). However, images can be deceptive and only solid, trustworthy statistics reveal the results we care for. Here, those results are consistent with what we (believe to) see in the pictures.  
The results for *SegOptim*, on the other hand, seem a bit odd in the first place as the higher accuracy was achieved by *SegOptim* using the RGB stack. But this resolves when thinking of it in detail: the algorithm did predict only a few pixels as *Fairy Ring*, making it less likely to make False-Positive-mistakes here. More mistakes were made by False-Negative prediction, marking *Fairy Rings* as *non Fairy Ring*. But as, in the end, the *Fairy Rings* make up the smaller part of the picture, these mistakes do not have that much of an impact onto the accuracy.  
The F1 values, on the other hand, do not take into account the right prediction of *non Fairy Ring* pixels but only the right prediction of *Fairy Rings*. Here, the results are the following:  
*U-Net*: **0.79**, *SegOptim* with full stack: **0.50**, *SegOptim* with RGB-stack: **0.38**  
Again, *U-Net* turns out to be way better in predicting the presence of *Fairy Ring* in the given section. In contrast to the accuracies, *SegOptim* performed worse when solely relying on the RGB-stack that it did when using the full stack, supporting was what mentioned before: in the *accuracy*, *SegOptims* poor RGB-only performance was masked by a lower number of *False-Negatives* with regard to *non Fairy Ring* pixels.  
However, all three models seemed to have had some trouble with the areas lower left corner. At that area the colours look a bit off, most likely due to a cloud passing this area while the drone was taking its pictures. The models, that did solely rely on the RGB-channels, did classify little to no *Fairy Ring* pixels here. The *SegOptim* model using the full stack on the other hand, classified a mess of *Fairy Ring* pixels with no recognisable structure. Looking at this area on the RGB-image with the help of the **God's view method** (<a href="https://www.uni-marburg.de/de/fb19/fachbereich/staff/dr-christoph-reudenbauch" target="_blank">Dr. Christoph Reudenbach</a>) it seems that there are *Fairy Rings*, but not that much. Hence, all three models struggled with properly identifying these, due to the strange colorspace. 

