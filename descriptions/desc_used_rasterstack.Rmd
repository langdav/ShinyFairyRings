---
title: "Untitled"
author: "David Langenohl"
date: "16 3 2021"
output: html_document
---

<style type="text/css">

body{ /* Normal  */
      font-size: 20px;
      font-family: "Times New Roman", Times, serif;
      color: Black;
  }
  
</style>

In "Research question" we presented you the area of interest for which we want to train our models and detect all those *Fairy Rings*. However, as training the algorithms is resource- and time-intensive, we decided to limit the area used for training to the extent you can see above. Moreover, the original image was shot by a drone and thus, had a rather high resolution of 1cm per pixel. As this high resolution is not crucial for the given task and to further reduce resource-intensity, we applied a mean value interpolation method to resample the image to a 10cm resolution. 

Now, the image we're using is an RGB-image, meaning it consists of 3 seperate layers: **R**ed, **G**reen and **B**lue. Each of those layers has a value range of 0-255; the intensity of the particular color ranges from 0 (= transparent) to 255 (strong red/green/blue). Then, all 3 layers stacked one over another result in the coloured image as you're seeing it (your eye is working in a similar manner, by the way).  

The *U-Net* method is satisfied with those 3 layers and, apart from the training areas, did not need any additional spectral or other information. *SegOptim* on the other hand is likely to show better results when it is fed with additional data. Hence, additional layers were calculated based on the 3 RGB-layers, using the R package <a href="https://gisma.github.io/uavRst/" target="_blank">*uavRst*</a>'s function *calc_ext*. We started by calculating the functions preset channels and then followed <a href="https://geomoer.github.io/moer-mpg-remote-sensing//unit05/unit04-07_spatial_trainingdata.html#some-aspects-of-reducing-predictors" target="_blank">this tutorial</a> to reduce the number of channels by checking the layer for intercorrelations and removing those containing too similar information. This resulted in in a 17 layer raster stack.  
As mentioned before, *U-Net* was provided with the RGB-layers only. For *SegOptim* on the other hand, two models were trained: one with the RGB-layers only, the other one with the 17-layer stack, resulting from the correlation test plus layers blue and red, which were initially sorted out by the test.  

In the little tool below you can click through the different layers of the 17-layer stack and get a short explanation of the particular channel. Also, the small image in the middel shows a visualization of the channel in a white-to-black color grade. The darker a particular pixel is, the bigger itsvalue is within the particular channels value range. By hovering over different pixels with your cursor, you can see their particular values. The tool also allows for zooming in, if you want a bigger picture of a specific area.


