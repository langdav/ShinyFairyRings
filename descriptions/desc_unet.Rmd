---
title: "Untitled"
author: "David Langenohl"
date: "16 3 2021"
output: html_document
---

<style type="text/css">

body{ /* Normal  */
      font-size: 20px;
      font-family: "Times New Roman", Times, serif;
      color: Black;
  }
  
</style>


*U-Net* is a convolutional neural network, developed for biomedical image segmentation at the Computer Science Department of the University of Freiburg (<a href="https://link.springer.com/content/pdf/10.1007%2F978-3-319-24574-4_28.pdf" target="_blank">Ronnenberger et al., 2015.</a>). The network consists of a contracting and an expansive path, giving it the u-shape. The contracting (downward) path is a convolutional network, consisting of repeated application of convolutions, each followed by a rectified linear unit (ReLU) and a max pooling operation. Here, spatial information is reduced while feature information is increased. On the expansive (upward) pathway, feature and spatial information are combined through a sequence of up-convolutions and concatenations with high-resolution features from the contracting path. For a more comprehensive explanation of how the algorithm workds, have a look into the video on the below.

The primary requisite for running a *U-Net* Algorithm is sufficient training data. For that, 20 randomly selected areas of the whole study area with a size of 256x256px were extracted. These were then labelled, which means that a mask was drawn over the image where 1 is *Fairy Ring* and 0 is *non Fairy Ring*. For machine learning algorithms, 20 labelled images is still very little since those algorithms can only be trained well with a lot of variance in the training data. To achieve this variance, the 20 images were augmented to synthetically achieve larger amounts of variation. During the augmentation different image manipulations are applied. The Image can be shifted, rotated, mirrored or the brightness can be altered. Doing this, 200 training images were generated from the original 20. 
The *U-Net* Model then worked through these 200 Images 10 times, each time (hopefully) improving over the last. After this, the model could be used to predict images that it did not know until that point.

If you are interested in how it is done, feel free to have a look at our <a href="https://github.com/langdav/EnvySys_FairyRings" target="_blank">GitHub repository.</a>



